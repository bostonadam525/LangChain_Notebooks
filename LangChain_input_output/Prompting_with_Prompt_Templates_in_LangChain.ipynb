{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompting with Prompt Templates for LLM Input/Output with LangChain\n",
        "* Notebook by Adam Lang\n",
        "* Date: 6/11/2024\n",
        "* In this notebook we will go over strategies and best practices for using Prompt Templates in LangChain for improving input/output through the \"chain\" from the LLM."
      ],
      "metadata": {
        "id": "N__4UvI25gzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "OIUJa1kU5vM0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH9aOATq5bmN",
        "outputId": "e467eaeb-df76-4895-ae3d-c3c5185a2ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.19\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.19)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain==0.1.19)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.52 (from langchain==0.1.19)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.19)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.19)\n",
            "  Downloading langsmith-0.1.77-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19)\n",
            "  Downloading orjson-3.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.19) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.19 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2 langsmith-0.1.77 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.4 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting langchain-openai==0.1.6\n",
            "  Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.6) (0.1.52)\n",
            "Collecting openai<2.0.0,>=1.24.0 (from langchain-openai==0.1.6)\n",
            "  Downloading openai-1.33.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai==0.1.6)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.1.77)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.7.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.12.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (3.10.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2.0.7)\n",
            "Installing collected packages: h11, tiktoken, httpcore, httpx, openai, langchain-openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain-openai-0.1.6 openai-1.33.0 tiktoken-0.7.0\n",
            "Requirement already satisfied: langchain-community==0.0.38 in /usr/local/lib/python3.10/dist-packages (0.0.38)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (0.1.52)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (0.1.77)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.38) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.38) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (2.7.3)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.38) (3.10.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.38) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.38) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.38) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.38) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.38) (4.12.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.38) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (2.18.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.38) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.1.19\n",
        "!pip install langchain-openai==0.1.6\n",
        "!pip install langchain-community==0.0.38"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter OpenAI key to call LLM"
      ],
      "metadata": {
        "id": "sktJLdcC596N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter your OpenAI API key please: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6Q2vZJ-54Vz",
        "outputId": "e8316581-295e-4464-c387-f4e641c0d231"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key please: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment variables for OpenAI"
      ],
      "metadata": {
        "id": "Ml4kIN6-6LFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ],
      "metadata": {
        "id": "hXy_rdJc6G_-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Models and LLMs\n",
        "* LLMs are of course a core component of LangChain.\n",
        "* LangChain acts as the interface or hub for LLMs to interact with your application and data. LangChain provides the standard APIs to do so.\n",
        "* The \"LLM Class\" is univerally designed to provide a standard API interface for any LLM to interact.\n",
        "\n",
        "## Commercial LLMs - ChatGPT"
      ],
      "metadata": {
        "id": "p2DLCngl6XjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)"
      ],
      "metadata": {
        "id": "Q7HAtaN06Tbq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Templates\n",
        "* A PromptTemplate is actually just a string template we can use to pass variables to in order to generate our final string.\n",
        "  * Essentially it is a \"recipe\" for generating language model prompts.\n",
        "  * These prompt templates can include:\n",
        "    * 1. instructions\n",
        "    * 2. few-shot examples\n",
        "    * 3. specific contexts and questions for particular tasks\n",
        "* We can then pass these PromptTemplates to any LLM in order to create consistently formatted prompts for the LLM to generate the desired output.\n",
        "* The great thing about LangChain is that it provides out of the box tools for creating and using prompt templates.\n",
        "  * These templates are LLM/model agnostic."
      ],
      "metadata": {
        "id": "BruO7Z9c69uS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template Types\n",
        "1. PromptTemplate\n",
        "  * Used for creating **string-based prompts.**\n",
        "  * Utilizes Python's `str.format` syntax for templating, supporting any number of variables, including scenarios with no variables.\n",
        "\n",
        "2. ChatPromptTemplate\n",
        "  * Designed for chat models where the prompt consists of a list of chat messages.\n",
        "  * Each chat message includes content and a role parameter.\n",
        "    * For example, in the OpenAI Chat Completions API these roles are:\n",
        "        * Assistant\n",
        "        * Human\n",
        "        * System\n",
        "\n",
        "3. FewShotChatMessagePromptTemplate\n",
        "  * Construct a few shot chat template from a set of examples."
      ],
      "metadata": {
        "id": "bBPlmUsDAkhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Template\n",
        "* Template for a string based prompt.\n",
        "* By default, uses Python's built in function `str.format` syntax for templating.\n",
        "* Create custom prompt templates that format the prompt any way you like."
      ],
      "metadata": {
        "id": "3YgGUmVfBcXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import PromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# very simple prompt example\n",
        "prompt = \"\"\"Explain to me what is a subarrachnoid hemorrhage in 3 bullet points?\"\"\"\n",
        "prompt_template = PromptTemplate.from_template(prompt)\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic3zKk1R68zR",
        "outputId": "755c4ea7-82e2-46a9-e5ea-abe487d29379"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=[], template='Explain to me what is a subarrachnoid hemorrhage in 3 bullet points?')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# format the prompt\n",
        "prompt_template.format()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DHHiQYJ5CCdU",
        "outputId": "e2253e23-3c2d-4f79-a2a1-7519d9692be7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Explain to me what is a subarrachnoid hemorrhage in 3 bullet points?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## invoke output response\n",
        "response = chatgpt.invoke(prompt_template.format())\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HPExw_TCFjr",
        "outputId": "4e792044-20ac-4d89-dd2c-1e61287b6d9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- A subarachnoid hemorrhage is a type of stroke caused by bleeding into the space surrounding the brain, known as the subarachnoid space.\n",
            "- This bleeding is often the result of a ruptured aneurysm, a weakened or bulging blood vessel in the brain that bursts and causes blood to leak into the subarachnoid space.\n",
            "- Symptoms of a subarachnoid hemorrhage can include sudden and severe headache, nausea, vomiting, neck stiffness, and loss of consciousness, and it is considered a medical emergency that requires immediate treatment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## more complex prompt with \"placeholders\"\n",
        "prompt = \"\"\"Explain to me briefly about {topic} in {language}.\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(prompt)\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KlImXn1CWmn",
        "outputId": "01c370b1-e301-4e3a-df53-8a96782848a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['language', 'topic'], template='Explain to me briefly about {topic} in {language}.')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list of tuples\n",
        "inputs = [('Generative AI', 'english'),\n",
        "          ('Artificial Intelligence', 'spanish'),\n",
        "          ('Deep Learning', 'japanese')]\n",
        "\n",
        "\n",
        "prompts = [prompt_template.format(topic=topic, language=language) for topic, language in inputs]\n",
        "prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG-vE7ctCt5b",
        "outputId": "0475e0ef-50ba-4da9-efbd-2cd7e99a81ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Explain to me briefly about Generative AI in english.',\n",
              " 'Explain to me briefly about Artificial Intelligence in spanish.',\n",
              " 'Explain to me briefly about Deep Learning in japanese.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## can use python .map() to invoke response\n",
        "responses = chatgpt.map().invoke(prompts)"
      ],
      "metadata": {
        "id": "_GOPUwIwDNhB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# responses\n",
        "responses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u2O5TARDvxP",
        "outputId": "43d52741-71c3-4432-c6ef-571a4afb056b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, that is original and not based on existing data. This technology uses algorithms to generate new content by learning patterns and styles from existing data sets. Generative AI has a wide range of applications, from creating realistic images to composing music, and is often used in creative fields such as art and design.', response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 19, 'total_tokens': 104}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cabe2309-6573-48af-b563-6f868a272476-0'),\n",
              " AIMessage(content='La inteligencia artificial es una rama de la informática que se enfoca en el desarrollo de sistemas y programas capaces de realizar tareas que normalmente requieren de la inteligencia humana, como el aprendizaje, la percepción, el razonamiento y la toma de decisiones. Estos sistemas utilizan algoritmos y técnicas avanzadas para simular el pensamiento humano y mejorar su desempeño con el tiempo. La inteligencia artificial se aplica en una amplia variedad de campos, como la medicina, la robótica, la industria, la educación y muchos otros, con el objetivo de automatizar procesos, mejorar la eficiencia y resolver problemas complejos.', response_metadata={'token_usage': {'completion_tokens': 151, 'prompt_tokens': 18, 'total_tokens': 169}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3dee038d-4528-4b54-9abe-50ad0bc119a6-0'),\n",
              " AIMessage(content='ディープラーニングは、人間の脳の仕組みを模倣した機械学習の一種です。多層のニューラルネットワークを使用して、複雑なパターンやデータを学習し、問題を解決する能力を持っています。ディープラーニングは、画像認識、音声認識、自然言語処理などの分野で広く活用されており、その性能は従来の機械学習手法よりも優れているとされています。', response_metadata={'token_usage': {'completion_tokens': 183, 'prompt_tokens': 18, 'total_tokens': 201}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8d88de44-1c2f-46af-bae0-17519c77f982-0')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## for loop to print each response\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pUwAlvuDzSP",
        "outputId": "da303503-91c0-4fca-c23c-e93d7873823c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative AI is a type of artificial intelligence that is capable of creating new content, such as images, text, or music, that is original and not based on existing data. This technology uses algorithms to generate new content by learning patterns and styles from existing data sets. Generative AI has a wide range of applications, from creating realistic images to composing music, and is often used in creative fields such as art and design.\n",
            "-----\n",
            "La inteligencia artificial es una rama de la informática que se enfoca en el desarrollo de sistemas y programas capaces de realizar tareas que normalmente requieren de la inteligencia humana, como el aprendizaje, la percepción, el razonamiento y la toma de decisiones. Estos sistemas utilizan algoritmos y técnicas avanzadas para simular el pensamiento humano y mejorar su desempeño con el tiempo. La inteligencia artificial se aplica en una amplia variedad de campos, como la medicina, la robótica, la industria, la educación y muchos otros, con el objetivo de automatizar procesos, mejorar la eficiencia y resolver problemas complejos.\n",
            "-----\n",
            "ディープラーニングは、人間の脳の仕組みを模倣した機械学習の一種です。多層のニューラルネットワークを使用して、複雑なパターンやデータを学習し、問題を解決する能力を持っています。ディープラーニングは、画像認識、音声認識、自然言語処理などの分野で広く活用されており、その性能は従来の機械学習手法よりも優れているとされています。\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatPromptTemplate\n",
        "* Standard prompt format to chat models is a list of chat messages.\n",
        "* Each chat message is associated with content and an additional parameter called `role`.\n",
        "  * For example, as mentioned above, in OpenAI Chat Completions API a chat message can be associated with an AI assistant, human or system role."
      ],
      "metadata": {
        "id": "yue9JmjZEVzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## simple example of ChatPromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# simple prompt with placeholders\n",
        "prompt = \"\"\"Explain to me briefly about {topic}.\"\"\"\n",
        "\n",
        "# instantiate chat_template\n",
        "chat_template = ChatPromptTemplate.from_template(prompt)\n",
        "chat_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0L2F7IIEIEs",
        "outputId": "5a7a8298-392d-4197-8184-59cbf01cb944"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='Explain to me briefly about {topic}.'))])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## make a list of topics to push to the LLM\n",
        "topics = ['Rocky Mountains','Green Mountains','Swiss Alps']\n",
        "prompts = [chat_template.format(topic=topic) for topic in topics]\n",
        "prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM8ucLc-Ez-k",
        "outputId": "10eed648-5d5d-4e2e-b717-e0321166c7e3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Human: Explain to me briefly about Rocky Mountains.',\n",
              " 'Human: Explain to me briefly about Green Mountains.',\n",
              " 'Human: Explain to me briefly about Swiss Alps.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## output response for all 3 prompts\n",
        "responses = chatgpt.map().invoke(prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWktRGYhFfJX",
        "outputId": "c8dca415-4aa4-4fe5-bca3-1df8951d2d6d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Rocky Mountains are a major mountain range in western North America, stretching over 3,000 miles from British Columbia in Canada to New Mexico in the United States. They are known for their rugged terrain, diverse wildlife, and stunning natural beauty. The Rockies are a popular destination for outdoor enthusiasts, offering opportunities for hiking, skiing, and wildlife viewing. They also play a crucial role in the region's ecosystem, providing habitat for a wide variety of plant and animal species.\n",
            "-------\n",
            "Green Mountains, also known as the Green Mountain Range, is a mountain range in the northeastern United States, primarily located in the state of Vermont. The range is part of the Appalachian Mountains and is known for its lush green forests, scenic beauty, and outdoor recreational opportunities such as hiking, skiing, and camping. The highest peak in the Green Mountains is Mount Mansfield, which reaches an elevation of 4,393 feet. The range is also home to the Long Trail, a popular hiking trail that runs the length of Vermont.\n",
            "-------\n",
            "The Swiss Alps are a mountain range located in Switzerland, known for their stunning beauty and popular tourist destinations. The Alps offer a wide range of outdoor activities such as skiing, hiking, and mountaineering. The region is also home to picturesque villages, charming chalets, and pristine lakes. The Swiss Alps are a popular destination for nature lovers and adventure seekers from around the world.\n",
            "-------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## let's view first response index\n",
        "responses[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAt_uI4tFzFy",
        "outputId": "81c70a6d-1e72-4020-98d6-03a121ab09cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"The Rocky Mountains are a major mountain range in western North America, stretching over 3,000 miles from British Columbia in Canada to New Mexico in the United States. They are known for their rugged terrain, diverse wildlife, and stunning natural beauty. The Rockies are a popular destination for outdoor enthusiasts, offering opportunities for hiking, skiing, and wildlife viewing. They also play a crucial role in the region's ecosystem, providing habitat for a wide variety of plant and animal species.\", response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 17, 'total_tokens': 111}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-754c9dc3-20d4-4ebc-b83f-6555660b4f2c-0')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## more complex prompt with a series of messages\n",
        "messages = [\n",
        "    ('system', \"You are an expert in NFL football history provide brief answers.\"),\n",
        "    ('human', 'what is your name?'),\n",
        "    ('ai', 'my name is AIBot'),\n",
        "    ('human', '{user_prompt}'),\n",
        "]\n",
        "\n",
        "# setup chat_template\n",
        "chat_template = ChatPromptTemplate.from_messages(messages)\n",
        "chat_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwcn1j-dF8rQ",
        "outputId": "fe67e4bb-7ca1-4d9e-ec10-923834843d33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['user_prompt'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an expert in NFL football history provide brief answers.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='what is your name?')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='my name is AIBot')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_prompt'], template='{user_prompt}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now create text prompts to feed to model\n",
        "text_prompts = [\"what is your name?\",\n",
        "                \"explain the Super Bowl to me\"]\n",
        "\n",
        "chat_prompts = [chat_template.format(user_prompt=prompt)\n",
        "                for prompt in text_prompts]\n",
        "chat_prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeo9T9dVGy_E",
        "outputId": "7f3196fc-2822-42ba-f62a-e3f7cc8c67b5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['System: You are an expert in NFL football history provide brief answers.\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: what is your name?',\n",
              " 'System: You are an expert in NFL football history provide brief answers.\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: explain the Super Bowl to me']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at first prompt\n",
        "print(chat_prompts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH3_UViYHdzv",
        "outputId": "628fa184-a60e-4337-cbab-14e66dbae778"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: You are an expert in NFL football history provide brief answers.\n",
            "Human: what is your name?\n",
            "AI: my name is AIBot\n",
            "Human: what is your name?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## now get the response\n",
        "responses = chatgpt.map().invoke(chat_prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzSpknrrHtA6",
        "outputId": "43776032-30d3-4e4b-d092-7e27c35e62c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: My name is AIBot\n",
            "-------\n",
            "AI: The Super Bowl is the championship game of the National Football League (NFL), played annually between the champions of the league's two conferences, the American Football Conference (AFC) and the National Football Conference (NFC). It is the culmination of the NFL season and is one of the most-watched sporting events in the United States.\n",
            "-------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now modify ChatPromptTemplate\n",
        "* list of messages different roles"
      ],
      "metadata": {
        "id": "Vgw2Hws5IMdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    ('system', 'You are an expert in NFL football history, provide detailed answers with examples.'),\n",
        "    ('human', 'what is your name?'),\n",
        "    ('ai', \"my name is AIBot\"),\n",
        "    ('human', '{user_prompt}'),\n",
        "]\n",
        "\n",
        "# setup chat template\n",
        "chat_template = ChatPromptTemplate.from_messages(messages)\n",
        "text_prompts = ['what is your name?', 'explain the Ice Bowl to me']\n",
        "chat_prompts = [chat_template.format(user_prompt=prompt) for prompt in text_prompts]\n",
        "chat_prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQx8maLFIEFl",
        "outputId": "f2cf24d9-1e9c-4035-ff15-6d00e22e684e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['System: You are an expert in NFL football history, provide detailed answers with examples.\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: what is your name?',\n",
              " 'System: You are an expert in NFL football history, provide detailed answers with examples.\\nHuman: what is your name?\\nAI: my name is AIBot\\nHuman: explain the Ice Bowl to me']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## for loop to invoke responses\n",
        "responses = chatgpt.map().invoke(chat_prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('---------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSmYf1zzI2_k",
        "outputId": "155a1016-2ebe-4eb9-d8ab-033409554fec"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: My name is AIBot\n",
            "---------\n",
            "The Ice Bowl refers to the NFL Championship Game played on December 31, 1967, between the Green Bay Packers and the Dallas Cowboys at Lambeau Field in Green Bay, Wisconsin. The game is famously known for being one of the coldest games in NFL history, with temperatures reaching -13°F (-25°C) and wind chills as low as -48°F (-44°C).\n",
            "\n",
            "The game was a hard-fought battle between two powerhouse teams, with the Packers ultimately winning 21-17. The most iconic moment of the game came in the final seconds when Packers quarterback Bart Starr scored the game-winning touchdown on a quarterback sneak, despite the freezing conditions and a slippery field covered in ice.\n",
            "\n",
            "The Ice Bowl is considered one of the greatest games in NFL history and is remembered for the extreme weather conditions, the toughness of the players, and the dramatic finish. It solidified the Packers' legacy as one of the greatest teams in NFL history and remains a legendary moment in football lore.\n",
            "---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PromptTemplate and ChatPromptTemplate BOTH support the LangChain LCEL\n",
        "* `PromptTemplate` and `ChatPromptTemplate` implement the \"runnable interface\" which is the basic building block of the LangChain Expression Language (LCEL). This means they support calls via:\n",
        "  * `invoke`\n",
        "  * `ainvoke`\n",
        "  * `stream`\n",
        "  * `astream`\n",
        "  * `batch`\n",
        "  * `abatch`\n",
        "  * `astream_log`\n",
        "\n",
        "* `PromptTemplate` accepts a dictionary (of the prompt variables) and returns a `StringPromptValue`.\n",
        "* A `ChatPromptTemplate` accepts a dictionary and returns a `ChatPromptValue`."
      ],
      "metadata": {
        "id": "NlX2MoxNJQKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup list of prompts\n",
        "text_prompts = ['what is your name?', 'explain what the west coast offense is']\n",
        "chat_prompts = [chat_template.invoke({'user_prompt' : prompt}) for prompt in text_prompts]\n",
        "chat_prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpWPyl0AJH2r",
        "outputId": "b80415cc-7910-4ec7-d006-82c6d586ec4f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ChatPromptValue(messages=[SystemMessage(content='You are an expert in NFL football history, provide detailed answers with examples.'), HumanMessage(content='what is your name?'), AIMessage(content='my name is AIBot'), HumanMessage(content='what is your name?')]),\n",
              " ChatPromptValue(messages=[SystemMessage(content='You are an expert in NFL football history, provide detailed answers with examples.'), HumanMessage(content='what is your name?'), AIMessage(content='my name is AIBot'), HumanMessage(content='explain what the west coast offense is')])]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompts[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPcvpGiRKTDN",
        "outputId": "f33687cd-5e94-407b-d1fe-a743c1f7bd13"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='You are an expert in NFL football history, provide detailed answers with examples.'), HumanMessage(content='what is your name?'), AIMessage(content='my name is AIBot'), HumanMessage(content='explain what the west coast offense is')])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this will output as formatted text\n",
        "print(chat_prompts[1].to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzirWYOfKVDR",
        "outputId": "824de6c3-c8f3-40ef-d6b6-bcee321f192e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System: You are an expert in NFL football history, provide detailed answers with examples.\n",
            "Human: what is your name?\n",
            "AI: my name is AIBot\n",
            "Human: explain what the west coast offense is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list of messages\n",
        "chat_prompts[1].to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lGGXOc7KkFW",
        "outputId": "f6a94e9e-b2d5-4ce5-ffcc-77e6e4de6e95"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessage(content='You are an expert in NFL football history, provide detailed answers with examples.'),\n",
              " HumanMessage(content='what is your name?'),\n",
              " AIMessage(content='my name is AIBot'),\n",
              " HumanMessage(content='explain what the west coast offense is')]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## get responses from LLM\n",
        "responses = chatgpt.map().invoke(chat_prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('----------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcmGgFl3K21r",
        "outputId": "d7da63d3-8773-491e-a22f-0dda5a9b6ae6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is AIBot\n",
            "----------\n",
            "The West Coast Offense is a style of offensive strategy in American football that was popularized by Bill Walsh, the former head coach of the San Francisco 49ers. It is characterized by short, quick passes that are designed to stretch the defense horizontally and create mismatches in space. The offense emphasizes precision timing between the quarterback and receivers, as well as the use of running backs and tight ends as receiving threats.\n",
            "\n",
            "Key principles of the West Coast Offense include:\n",
            "\n",
            "1. Short, high-percentage passes: Quarterbacks in the West Coast Offense are trained to make quick reads and get the ball out of their hands rapidly to receivers running short routes. This helps to move the chains and sustain drives.\n",
            "\n",
            "2. Timing and rhythm: Receivers are expected to run precise routes and be in the right spot at the right time to catch the ball. Quarterbacks must have a strong understanding of the offense and be able to anticipate where their receivers will be.\n",
            "\n",
            "3. Yards after the catch: The West Coast Offense relies on receivers gaining yards after the catch by using their speed and agility to make defenders miss. This can turn short passes into big gains.\n",
            "\n",
            "4. Ball control: By utilizing short passes and a quick tempo, the West Coast Offense aims to control the clock and keep the opposing offense off the field.\n",
            "\n",
            "An example of a team that successfully implemented the West Coast Offense is the 1980s San Francisco 49ers, led by Hall of Fame quarterback Joe Montana. The 49ers won multiple Super Bowls using this offensive system, which revolutionized the way the game was played.\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FewShotChatMessagePromptTemplate\n",
        "* This is a Chat prompt template that supports few-shot examples.\n",
        "* The high level structure of produced by this prompt template is a list of messages of prefix message(s), example message(s), and suffix message(s).\n",
        "* This structure enables creating a conversation with intermediate examples such as:\n",
        "  * `System: You are a helpful AI assistant`\n",
        "  * `Human: What is 5 + 5`\n",
        "  * `AI: 10`\n",
        "  * `Human: What is 6*8`\n",
        "  * `AI: 48`\n",
        "  * `Human: What is 10 - 2`\n",
        "* The idea is that you give the system a few shot examples and then it has context to hopefully answer your prompts."
      ],
      "metadata": {
        "id": "ga35t6s9LWJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the few-shot examples you would like to include"
      ],
      "metadata": {
        "id": "VcUG74mIMNIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "# load up few shot examples\n",
        "example_data = [\n",
        "    (\"\"\"Wimbledon 1999 Men's final.\n",
        "    Two-time defending champion Pete Sampras defeated Andre Agassi in the final, 6–3, 6–4, 7–5 to win the gentlemen's singles tennis title\"\"\",\n",
        "     'Sports'),\n",
        "\n",
        "    (\"\"\"US shocks soviets in ice hockey 4-3\"\"\",\n",
        "     'Sports'),\n",
        "\n",
        "    (\"\"\"On January 28, 1986, the NASA shuttle orbiter mission STS-51-L and the tenth flight of Space Shuttle Challenger (OV-99) broke apart 73 seconds into its flight, killing all seven crew members, which consisted of five NASA astronauts and two payload specialists. The spacecraft disintegrated over the Atlantic Ocean, off the coast of Cape Canaveral, Florida, at 11:39 EST (16:39 UTC).\"\"\",\n",
        "     'Space Exploration'),\n",
        "\n",
        "    (\"\"\"Scores killed as terrorist's car bomb blows up block-long Oklahoma City federal building (April 19); Timothy McVeigh, 27, arrested as suspect (April 21); authorities seek second suspect, link right-wing paramilitary groups to bombing (April 22).\"\"\",\n",
        "     'US Events')\n",
        "]\n",
        "\n",
        "example_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYhrctEHLKWC",
        "outputId": "f1f27191-069f-482a-b30f-d811d4d79021"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"Wimbledon 1999 Men's final. \\n    Two-time defending champion Pete Sampras defeated Andre Agassi in the final, 6–3, 6–4, 7–5 to win the gentlemen's singles tennis title\",\n",
              "  'Sports'),\n",
              " ('US shocks soviets in ice hockey 4-3', 'Sports'),\n",
              " ('On January 28, 1986, the NASA shuttle orbiter mission STS-51-L and the tenth flight of Space Shuttle Challenger (OV-99) broke apart 73 seconds into its flight, killing all seven crew members, which consisted of five NASA astronauts and two payload specialists. The spacecraft disintegrated over the Atlantic Ocean, off the coast of Cape Canaveral, Florida, at 11:39 EST (16:39 UTC).',\n",
              "  'Space Exploration'),\n",
              " (\"Scores killed as terrorist's car bomb blows up block-long Oklahoma City federal building (April 19); Timothy McVeigh, 27, arrested as suspect (April 21); authorities seek second suspect, link right-wing paramilitary groups to bombing (April 22).\",\n",
              "  'US Events')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## each tuple becomes a dictionary -- formatted\n",
        "example_data_formatted = [{'input': input, 'output': output}\n",
        "                          for input, output in example_data]\n",
        "\n",
        "example_data_formatted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yka6V_aBQ38L",
        "outputId": "87dbbd86-5624-4542-c4d4-36786c02aa73"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'input': \"Wimbledon 1999 Men's final. \\n    Two-time defending champion Pete Sampras defeated Andre Agassi in the final, 6–3, 6–4, 7–5 to win the gentlemen's singles tennis title\",\n",
              "  'output': 'Sports'},\n",
              " {'input': 'US shocks soviets in ice hockey 4-3', 'output': 'Sports'},\n",
              " {'input': 'On January 28, 1986, the NASA shuttle orbiter mission STS-51-L and the tenth flight of Space Shuttle Challenger (OV-99) broke apart 73 seconds into its flight, killing all seven crew members, which consisted of five NASA astronauts and two payload specialists. The spacecraft disintegrated over the Atlantic Ocean, off the coast of Cape Canaveral, Florida, at 11:39 EST (16:39 UTC).',\n",
              "  'output': 'Space Exploration'},\n",
              " {'input': \"Scores killed as terrorist's car bomb blows up block-long Oklahoma City federal building (April 19); Timothy McVeigh, 27, arrested as suspect (April 21); authorities seek second suspect, link right-wing paramilitary groups to bombing (April 22).\",\n",
              "  'output': 'US Events'}]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assemble few shot examples into few shot prompt template"
      ],
      "metadata": {
        "id": "u3a-ttuARa9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        ('human','{input}'),\n",
        "        ('ai', '{output}'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=data_prompt,\n",
        "    examples=example_data_formatted,\n",
        ")\n",
        "\n",
        "few_shot_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vskia3IqRTIT",
        "outputId": "7fdc5550-731e-4550-b21e-2a984d066d45"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FewShotChatMessagePromptTemplate(examples=[{'input': \"Wimbledon 1999 Men's final. \\n    Two-time defending champion Pete Sampras defeated Andre Agassi in the final, 6–3, 6–4, 7–5 to win the gentlemen's singles tennis title\", 'output': 'Sports'}, {'input': 'US shocks soviets in ice hockey 4-3', 'output': 'Sports'}, {'input': 'On January 28, 1986, the NASA shuttle orbiter mission STS-51-L and the tenth flight of Space Shuttle Challenger (OV-99) broke apart 73 seconds into its flight, killing all seven crew members, which consisted of five NASA astronauts and two payload specialists. The spacecraft disintegrated over the Atlantic Ocean, off the coast of Cape Canaveral, Florida, at 11:39 EST (16:39 UTC).', 'output': 'Space Exploration'}, {'input': \"Scores killed as terrorist's car bomb blows up block-long Oklahoma City federal building (April 19); Timothy McVeigh, 27, arrested as suspect (April 21); authorities seek second suspect, link right-wing paramilitary groups to bombing (April 22).\", 'output': 'US Events'}], example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], template='{output}'))]))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## actual few shot prompt\n",
        "print(few_shot_prompt.format())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8Dk_T-jR49G",
        "outputId": "3f253bb0-8df1-49c6-b2d2-b1d40437ce1f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Wimbledon 1999 Men's final. \n",
            "    Two-time defending champion Pete Sampras defeated Andre Agassi in the final, 6–3, 6–4, 7–5 to win the gentlemen's singles tennis title\n",
            "AI: Sports\n",
            "Human: US shocks soviets in ice hockey 4-3\n",
            "AI: Sports\n",
            "Human: On January 28, 1986, the NASA shuttle orbiter mission STS-51-L and the tenth flight of Space Shuttle Challenger (OV-99) broke apart 73 seconds into its flight, killing all seven crew members, which consisted of five NASA astronauts and two payload specialists. The spacecraft disintegrated over the Atlantic Ocean, off the coast of Cape Canaveral, Florida, at 11:39 EST (16:39 UTC).\n",
            "AI: Space Exploration\n",
            "Human: Scores killed as terrorist's car bomb blows up block-long Oklahoma City federal building (April 19); Timothy McVeigh, 27, arrested as suspect (April 21); authorities seek second suspect, link right-wing paramilitary groups to bombing (April 22).\n",
            "AI: US Events\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now assemble final prompt and use with LLM"
      ],
      "metadata": {
        "id": "yYJUPg9GSUNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        ('system', 'Classify every new news article using a similar format as shown below'),\n",
        "        few_shot_prompt,\n",
        "        ('human', '{input}'),\n",
        "    ]\n",
        ")\n",
        "final_prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dccjmByESNuu",
        "outputId": "526a469b-f8f7-4f09-f163-68009c7752f7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Classify every new news article using a similar format as shown below')), FewShotChatMessagePromptTemplate(examples=[{'input': \"Wimbledon 1999 Men's final. \\n    Two-time defending champion Pete Sampras defeated Andre Agassi in the final, 6–3, 6–4, 7–5 to win the gentlemen's singles tennis title\", 'output': 'Sports'}, {'input': 'US shocks soviets in ice hockey 4-3', 'output': 'Sports'}, {'input': 'On January 28, 1986, the NASA shuttle orbiter mission STS-51-L and the tenth flight of Space Shuttle Challenger (OV-99) broke apart 73 seconds into its flight, killing all seven crew members, which consisted of five NASA astronauts and two payload specialists. The spacecraft disintegrated over the Atlantic Ocean, off the coast of Cape Canaveral, Florida, at 11:39 EST (16:39 UTC).', 'output': 'Space Exploration'}, {'input': \"Scores killed as terrorist's car bomb blows up block-long Oklahoma City federal building (April 19); Timothy McVeigh, 27, arrested as suspect (April 21); authorities seek second suspect, link right-wing paramilitary groups to bombing (April 22).\", 'output': 'US Events'}], example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], template='{output}'))])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we feed the LLM new news articles and ask it to classify based on the few shot prompts"
      ],
      "metadata": {
        "id": "Tk6CaiTiS3Xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\"\"\"The Los Angeles Lakers offered Dan Hurley what would have seemed like a basketball coach’s dream: a chance to coach one of the world’s most popular franchises, possibly an opportunity to work with LeBron James and a salary that would have doubled his current one.\"\"\",\n",
        "        \"\"\"Nasa says its Perseverance rover has essentially completed the job it was asked to do when it landed on Mars in February 2021.\n",
        "\n",
        "The robot's basic requirement was to survey an ancient crater lake and to collect rocks that would aid the quest to identify evidence for past life.\n",
        "This primary objective had been accomplished, the mission team told a major conference in San Francisco.\n",
        "The announcement was made on the 1,000th Martian day of the mission.\"\"\"]\n",
        "\n",
        "\n",
        "final_prompts = [final_prompt_template.format(input=doc) for doc in docs]\n",
        "responses = chatgpt.map().invoke(final_prompts)"
      ],
      "metadata": {
        "id": "o8i0EL00SolZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# responses\n",
        "responses[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28_YP0ZuT2Nk",
        "outputId": "7c24f9f7-b44e-40a3-f9b9-04dc386285c1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='AI: Sports', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 309, 'total_tokens': 312}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3f68c48a-19e4-405f-b69c-5763757d1c5c-0')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for loop output\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('----------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFZ3gDAlT4s3",
        "outputId": "5af18cd5-7de8-4cd6-b07e-782b904b0e4e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: Sports\n",
            "----------\n",
            "AI: Space Exploration\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "* We can see that the AI classification was correct based off our few shot templates."
      ],
      "metadata": {
        "id": "NTGTTC-hUHYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partial Prompt Templates\n",
        "* Just as in other methods, it can make sense to \"partial\" a prompt template -- eg pass in a subset of the required data values as to create a new prompt template which expects only remaining subset of data values.\n",
        "\n",
        "* You can use the `partial` function to add some input data first and the rest of the input data later."
      ],
      "metadata": {
        "id": "9PPFvz31UNjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# function to get current datetime\n",
        "def get_datetime():\n",
        "  now = datetime.now()\n",
        "  return now.strftime(\"%m/%d/%Y\")"
      ],
      "metadata": {
        "id": "NSiXrnOvUBgN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_txt = \"\"\"Tell me a joke about {topic} on the day {date}\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_txt)"
      ],
      "metadata": {
        "id": "XyhPWERzU3RE"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt.partial(date=get_datetime)\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy9VZ_R3VBRb",
        "outputId": "bd33ca35-008a-43bb-992c-2ee47ae1e777"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], partial_variables={'date': <function get_datetime at 0x7dcd010c6b00>}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['date', 'topic'], template='Tell me a joke about {topic} on the day {date}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## lets give topics\n",
        "topics = ['Plumbers', 'Electricians']\n",
        "final_prompts = [prompt.format(topic=topic) for topic in topics]\n",
        "final_prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eckZuoW6VE4-",
        "outputId": "daa8f388-99c8-47fd-f93d-4bcb8775d5e4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Human: Tell me a joke about Plumbers on the day 06/12/2024',\n",
              " 'Human: Tell me a joke about Electricians on the day 06/12/2024']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get response\n",
        "responses = chatgpt.map().invoke(final_prompts)\n",
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4PQkzmQViyN",
        "outputId": "e0bd971a-55c3-4bce-f4a0-2287e5ad5cc4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the plumber break up with his girlfriend? Because he found out she was just draining him of his money!\n",
            "-----------\n",
            "Why did the electrician bring a ladder to the job on 06/12/2024? Because he heard the job was electrifying!\n",
            "-----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88_NYwc1Vqvt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}