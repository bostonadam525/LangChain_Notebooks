{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Building a Research Paper Analyst with Prompt Engineering\n",
        "* Notebook by Adam Lang\n",
        "* Date: 6/27/2024\n",
        "\n",
        "# Overview\n",
        "* This is a mini-project using GPT models and LangChain to build a Research Paper Analyst with Prompt Engineering.\n",
        "* As in the previous project we will use ChatGPT API but also output parsers in LangChain."
      ],
      "metadata": {
        "id": "XcJ6sBDOr24-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "wvyCpBX2sRBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZwYp_6ZrxHh",
        "outputId": "b7e43c77-3c1d-4164-b954-f4966b569724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.19\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.19)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain==0.1.19)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.52 (from langchain==0.1.19)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.19)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.19)\n",
            "  Downloading langsmith-0.1.82-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.19) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.19)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.19)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.19 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2 langsmith-0.1.82 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.5 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting langchain-openai==0.1.6\n",
            "  Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.6) (0.1.52)\n",
            "Collecting openai<2.0.0,>=1.24.0 (from langchain-openai==0.1.6)\n",
            "  Downloading openai-1.35.6-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai==0.1.6)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.1.82)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.7.4)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (8.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2.0.7)\n",
            "Installing collected packages: h11, tiktoken, httpcore, httpx, openai, langchain-openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain-openai-0.1.6 openai-1.35.6 tiktoken-0.7.0\n",
            "Requirement already satisfied: langchain-community==0.0.38 in /usr/local/lib/python3.10/dist-packages (0.0.38)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (0.1.52)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (0.1.82)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.0.38) (8.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.38) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.38) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.38) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (2.7.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.38) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.38) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.38) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.38) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.0.38) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.38) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.38) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.52->langchain-community==0.0.38) (2.18.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.38) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "!pip install langchain==0.1.19\n",
        "!pip install langchain-openai==0.1.6\n",
        "!pip install langchain-community==0.0.38"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Tokens\n",
        "* Open AI access"
      ],
      "metadata": {
        "id": "oYB4Uko-sYRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## enter the API key\n",
        "from getpass import getpass\n",
        "\n",
        "\n",
        "OPENAI_KEY = getpass('Enter your Open AI key: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDP0BiR7sWR9",
        "outputId": "f4e831f3-c52e-42bb-991f-7b343a2deea0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Open AI key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## openai environment variables\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ],
      "metadata": {
        "id": "ICOSiF8Dsi-x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Dependencies"
      ],
      "metadata": {
        "id": "xPGu2vyrssQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## imports\n",
        "from langchain_core.prompts import ChatPromptTemplate # prompt templates from langchain\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "xEdXcue6srQf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate chatgpt instance\n",
        "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0) # less randomness"
      ],
      "metadata": {
        "id": "5XSZK7C8s3y0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Building a Research Paper Analyst\n",
        "Scenario: Let's build an application using LangChain and ChatGPT to analyze Research paper abstracts. The application will do the following:\n",
        "1. Write a short summary maximum 10 lines for a general audience based on the input research paper abstract.\n",
        "2. Give a detailed report for a healthcare company with bullet points for pros and cons of the ethics of using Generative AI found in the paper.\n",
        "3. Give a detailed report for a Generative AI company solving healthcare problems and use bullet points for key issues mentioned for Gen AI for text, images and structured healthcare data.\n",
        "\n",
        "Goal:\n",
        "1. We will try to use the `ChatPromptTemplate` to have a conversation with ChatGPT for each task above and \"talk to the data\".\n",
        "2. Each of the scenario points above would be outputs for a different level of stakeholder or audience."
      ],
      "metadata": {
        "id": "NpfCky-4tEcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Research Paper Abstract"
      ],
      "metadata": {
        "id": "sNEEZZ3vuBVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paper_abstract = f\"\"\"\n",
        "The widespread use of ChatGPT and other emerging technology powered by generative\n",
        "artificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\n",
        "high-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\n",
        "issues beyond following guidelines and regulations that are still under discussion and\n",
        "development. On the other hand, other types of generative AI have been used to synthesize\n",
        "images and other types of data for research and practical purposes, which have resolved some\n",
        "ethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\n",
        "of ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\n",
        "generative AI via a systematic scoping review of relevant existing research in healthcare, and\n",
        "reduce the gaps by proposing an ethics checklist for comprehensive assessment and\n",
        "transparent documentation of ethical discussions in generative AI development. While the\n",
        "checklist can be readily integrated into the current peer review and publication system to\n",
        "enhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\n",
        "products) to help users establish reasonable trust in their capabilities.\n",
        "\n",
        "Current ethical discussions on generative AI in healthcare\n",
        "We conducted a systematic scoping review to analyse current ethical discussions on\n",
        "generative AI in healthcare. Our search in four major academic research databases for\n",
        "relevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\n",
        "detailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\n",
        "which 193 articles were included for analysis based on application data modality (text, image,\n",
        "or structured data), ethical issues discussed, generative AI involved, and whether generative\n",
        "AI causes or offers technical solutions for issues raised.\n",
        "\n",
        "Generative AI for text data-based healthcare\n",
        "Forty-one of the 193 articles discussed ethical considerations pertaining to generative AI\n",
        "applications for text data, with 20 articles describing methodological developments or\n",
        "applications of generative AI and the other 21 articles describing review-type works on this\n",
        "topic. Although some of these review-type articles used the general term “generative AI”, the\n",
        "main body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\n",
        "discussions on ethical issues, whereas the other 12 articles only briefly touched on some\n",
        "ethical aspects.\n",
        "Among the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\n",
        "specifically by GPT in 16 of the articles), covering a wide range of application scenarios and\n",
        "considered the application of all 10 ethical principles identified in the review (see Figure 1),\n",
        "as well as other less discussed concerns such as human-AI interaction, and the rights of\n",
        "LLMs to be considered as co-authors in scientific papers. One paper only commented briefly\n",
        "on the need for ethical considerations in LLMs and is summarised in the “Others” category.\n",
        "Although all ethical principles are equally important, some are discussed more often than\n",
        "others, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\n",
        "privacy.\n",
        "Fifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\n",
        "confidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\n",
        "autoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\n",
        "medical text, to reduce disparity by providing accessible services and assistance, to detect\n",
        "health-related misinformation, to generate trusted content, and to improve accountability or\n",
        "transparency over existing approaches. While most articles focused on either identifying\n",
        "ethical issues caused by generative AI or proposing generative AI-based solutions, three\n",
        "articles discussed both to provide a more balanced perspective.\n",
        "\n",
        "Generative AI for image and structured data-based healthcare\n",
        "Unlike the diverse application scenarios of generative AI based on text data, for image and\n",
        "structured data, this use of generative AI focuses on data synthesis and encryption. Hence the\n",
        "majority of articles discussed the methodological developments of generative AI as giving\n",
        "rise to a more distinctive and focused set of ethical issues.\n",
        "5\n",
        "Notably, of the 98 articles on image data and 58 articles on structured data, more than half\n",
        "(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\n",
        "brief motivation for methodological developments or as a general discussion point. The rest\n",
        "included more in-depth discussions or evaluations of ethical issues. Among these 155 articles\n",
        "(as one article covered multiple modalities), 11 articles were review-type work, where 10\n",
        "articles reviewed methods that mentioned one or two ethical perspectives, and only one\n",
        "article24 discussed detailed ethical concerns on generative AI applications.\n",
        "Resolving privacy issues was the main aim of articles for these two data modalities (n=74 for\n",
        "image data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\n",
        "data using GAN. Eight articles on image data and 9 articles on structured data used\n",
        "generative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\n",
        "existing databases. For both data modalities, we did not see explicit discussions on resolving\n",
        "autonomy, integrity, or morality issues using generative AI, and for structured data the articles\n",
        "additionally lacked discussions on trust or transparency.\n",
        "Only 11 articles for image data selectively discussed some ethical issues that generative AI\n",
        "can give rise to, without specific discussions regarding autonomy, integrity, or morality. For\n",
        "structured data, only 4 articles discussed equity, privacy, or data security issues caused by\n",
        "generative AI. Only two articles on structured data included both the cause and resolving\n",
        "perspectives by discussing ethical issues that may arise from limitations of methods\n",
        "proposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_2so539-tA7o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(paper_abstract))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YyjZJISuPvi",
        "outputId": "9261da32-eaa7-4d55-cdbe-ea85dd388498"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see this is a pretty big abstract with 6,230 characters."
      ],
      "metadata": {
        "id": "iTAdWUa8vTf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template creation\n",
        "* Research paper analysis\n",
        "* Transformation"
      ],
      "metadata": {
        "id": "5fn0edTdvbZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## using a system prompt role for ChatGPT\n",
        "SYS_PROMPT = \"\"\"\n",
        "You are an expert in Artificial Intelligence or AI.\n",
        "Your job is to transform the input data which is a research paper abstract given below\n",
        "based on the instruction input by the user.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## prompt instantiation for Chat\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        (\"human\", \"{instruction}\"),\n",
        "\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "JYwiWOKpvQRR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LCEL LLM Chain Creation\n",
        "* No output parser is needed --> we are not generating any structured output."
      ],
      "metadata": {
        "id": "HDRSy-gXwRsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## LCEL chain\n",
        "chain = (prompt\n",
        "           |\n",
        "         chatgpt)"
      ],
      "metadata": {
        "id": "3QcM_3gPwITf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Summary Report #1\n",
        "* Below we are using `HumanMessage` which is for generating \"human like output\" which would be stored for conversational messages rather than direct output."
      ],
      "metadata": {
        "id": "BoWoqDxxwgIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "prompt_txt = f\"\"\"\n",
        "Based on the following research paper abstract,\n",
        "create a summary report of maximum 10 lines\n",
        "for a general audience of stakeholders\n",
        "\n",
        "Abstract:\n",
        "{paper_abstract}\n",
        "\"\"\"\n",
        "\n",
        "print(prompt_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOAIPYqh1ltV",
        "outputId": "790e880a-3adb-4285-9a1c-d12740d7afaf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Based on the following research paper abstract,\n",
            "create a summary report of maximum 10 lines\n",
            "for a general audience of stakeholders\n",
            "\n",
            "Abstract:\n",
            "\n",
            "The widespread use of ChatGPT and other emerging technology powered by generative\n",
            "artificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\n",
            "high-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\n",
            "issues beyond following guidelines and regulations that are still under discussion and\n",
            "development. On the other hand, other types of generative AI have been used to synthesize\n",
            "images and other types of data for research and practical purposes, which have resolved some\n",
            "ethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\n",
            "of ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\n",
            "generative AI via a systematic scoping review of relevant existing research in healthcare, and\n",
            "reduce the gaps by proposing an ethics checklist for comprehensive assessment and\n",
            "transparent documentation of ethical discussions in generative AI development. While the\n",
            "checklist can be readily integrated into the current peer review and publication system to\n",
            "enhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\n",
            "products) to help users establish reasonable trust in their capabilities.\n",
            "\n",
            "Current ethical discussions on generative AI in healthcare\n",
            "We conducted a systematic scoping review to analyse current ethical discussions on\n",
            "generative AI in healthcare. Our search in four major academic research databases for\n",
            "relevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\n",
            "detailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\n",
            "which 193 articles were included for analysis based on application data modality (text, image,\n",
            "or structured data), ethical issues discussed, generative AI involved, and whether generative\n",
            "AI causes or offers technical solutions for issues raised.\n",
            "\n",
            "Generative AI for text data-based healthcare\n",
            "Forty-one of the 193 articles discussed ethical considerations pertaining to generative AI\n",
            "applications for text data, with 20 articles describing methodological developments or\n",
            "applications of generative AI and the other 21 articles describing review-type works on this\n",
            "topic. Although some of these review-type articles used the general term “generative AI”, the\n",
            "main body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\n",
            "discussions on ethical issues, whereas the other 12 articles only briefly touched on some\n",
            "ethical aspects.\n",
            "Among the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\n",
            "specifically by GPT in 16 of the articles), covering a wide range of application scenarios and\n",
            "considered the application of all 10 ethical principles identified in the review (see Figure 1),\n",
            "as well as other less discussed concerns such as human-AI interaction, and the rights of\n",
            "LLMs to be considered as co-authors in scientific papers. One paper only commented briefly\n",
            "on the need for ethical considerations in LLMs and is summarised in the “Others” category.\n",
            "Although all ethical principles are equally important, some are discussed more often than\n",
            "others, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\n",
            "privacy.\n",
            "Fifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\n",
            "confidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\n",
            "autoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\n",
            "medical text, to reduce disparity by providing accessible services and assistance, to detect\n",
            "health-related misinformation, to generate trusted content, and to improve accountability or\n",
            "transparency over existing approaches. While most articles focused on either identifying\n",
            "ethical issues caused by generative AI or proposing generative AI-based solutions, three\n",
            "articles discussed both to provide a more balanced perspective.\n",
            "\n",
            "Generative AI for image and structured data-based healthcare\n",
            "Unlike the diverse application scenarios of generative AI based on text data, for image and\n",
            "structured data, this use of generative AI focuses on data synthesis and encryption. Hence the\n",
            "majority of articles discussed the methodological developments of generative AI as giving\n",
            "rise to a more distinctive and focused set of ethical issues.\n",
            "5\n",
            "Notably, of the 98 articles on image data and 58 articles on structured data, more than half\n",
            "(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\n",
            "brief motivation for methodological developments or as a general discussion point. The rest\n",
            "included more in-depth discussions or evaluations of ethical issues. Among these 155 articles\n",
            "(as one article covered multiple modalities), 11 articles were review-type work, where 10\n",
            "articles reviewed methods that mentioned one or two ethical perspectives, and only one\n",
            "article24 discussed detailed ethical concerns on generative AI applications.\n",
            "Resolving privacy issues was the main aim of articles for these two data modalities (n=74 for\n",
            "image data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\n",
            "data using GAN. Eight articles on image data and 9 articles on structured data used\n",
            "generative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\n",
            "existing databases. For both data modalities, we did not see explicit discussions on resolving\n",
            "autonomy, integrity, or morality issues using generative AI, and for structured data the articles\n",
            "additionally lacked discussions on trust or transparency.\n",
            "Only 11 articles for image data selectively discussed some ethical issues that generative AI\n",
            "can give rise to, without specific discussions regarding autonomy, integrity, or morality. For\n",
            "structured data, only 4 articles discussed equity, privacy, or data security issues caused by\n",
            "generative AI. Only two articles on structured data included both the cause and resolving\n",
            "perspectives by discussing ethical issues that may arise from limitations of methods\n",
            "proposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# prompt sent as a \"human\"\n",
        "prompt_txt = f\"\"\"\n",
        "Based on the following research paper abstract,\n",
        "create a summary report of maximum 10 lines\n",
        "for a general audience of stakeholders\n",
        "\n",
        "Abstract:\n",
        "{paper_abstract}\n",
        "\"\"\"\n",
        "\n",
        "# store human message in an empty list --> store chat history\n",
        "messages = [HumanMessage(content=prompt_txt)]\n",
        "\n",
        "## sent as a user instruction to the LLM\n",
        "user_instruction = {'instruction': messages}\n",
        "\n",
        "# invoke chain response\n",
        "response = chain.invoke(user_instruction)\n",
        "messages.append(response)"
      ],
      "metadata": {
        "id": "o4K0bnWNwXzv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## print response (10 line summary)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFp-EMAlxEp9",
        "outputId": "f451ec69-9c37-4620-9a41-c7d3f89a64b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Report:\n",
            "\n",
            "The use of generative artificial intelligence (AI), such as ChatGPT, in high-stakes applications like healthcare has raised ethical concerns. While guidelines and regulations are still evolving, there is a need to address gaps in ethical discussions. A systematic review highlighted the importance of an ethics checklist for transparent documentation in generative AI development. \n",
            "\n",
            "In healthcare, generative AI is being used for text, image, and structured data. Ethical considerations vary across these modalities, with a focus on issues like privacy, bias reduction, and misinformation detection. While some articles propose solutions using generative AI, others highlight ethical dilemmas caused by these technologies. \n",
            "\n",
            "For image and structured data, privacy concerns are a key focus, with efforts to generate synthetic data to mitigate risks. However, discussions on autonomy, integrity, and morality issues are lacking. Overall, there is a need for comprehensive ethical assessments and transparency in the development of generative AI-powered products for healthcare applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "jw-o7ubL2F2g",
        "outputId": "1239fe81-e49a-40d9-8f75-f064519de324"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Summary Report:\\n\\nThe use of generative artificial intelligence (AI), such as ChatGPT, in high-stakes applications like healthcare has raised ethical concerns. While guidelines and regulations are still evolving, there is a need to address gaps in ethical discussions. A systematic review highlighted the importance of an ethics checklist for transparent documentation in generative AI development. \\n\\nIn healthcare, generative AI is being used for text, image, and structured data. Ethical considerations vary across these modalities, with a focus on issues like privacy, bias reduction, and misinformation detection. While some articles propose solutions using generative AI, others highlight ethical dilemmas caused by these technologies. \\n\\nFor image and structured data, privacy concerns are a key focus, with efforts to generate synthetic data to mitigate risks. However, discussions on autonomy, integrity, and morality issues are lacking. Overall, there is a need for comprehensive ethical assessments and transparency in the development of generative AI-powered products for healthcare applications.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## lets look at a list of messages stored\n",
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMmc6QRF2Ibf",
        "outputId": "99a16398-54ae-4bc0-8e28-a91a802f5948"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate a summary report of maximum 10 lines\\nfor a general audience of stakeholders\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term “generative AI”, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the “Others” category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n'),\n",
              " AIMessage(content='Summary Report:\\n\\nThe use of generative artificial intelligence (AI), such as ChatGPT, in high-stakes applications like healthcare has raised ethical concerns. While guidelines and regulations are still evolving, there is a need to address gaps in ethical discussions. A systematic review highlighted the importance of an ethics checklist for transparent documentation in generative AI development. \\n\\nIn healthcare, generative AI is being used for text, image, and structured data. Ethical considerations vary across these modalities, with a focus on issues like privacy, bias reduction, and misinformation detection. While some articles propose solutions using generative AI, others highlight ethical dilemmas caused by these technologies. \\n\\nFor image and structured data, privacy concerns are a key focus, with efforts to generate synthetic data to mitigate risks. However, discussions on autonomy, integrity, and morality issues are lacking. Overall, there is a need for comprehensive ethical assessments and transparency in the development of generative AI-powered products for healthcare applications.', response_metadata={'token_usage': {'completion_tokens': 195, 'prompt_tokens': 1334, 'total_tokens': 1529}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-143e4b64-8ade-4a2b-ac1c-94888c052995-0')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "* What we see above is the prompt --> then the LLM response"
      ],
      "metadata": {
        "id": "Zf9v-sYh2Ryj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgDapsxi2RWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Summary Report #2\n",
        "* Now we don't have to generate this message again and again, we stored it as a HumanMessage.\n",
        "* We do have to create a new prompt though to generate the 2nd report summary."
      ],
      "metadata": {
        "id": "-gFiW9QhyDqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## prompt 2\n",
        "prompt_txt = f\"\"\"\n",
        "Use only the research paper abstract from earlier and create a detailed report for a healthcare company.\n",
        "In the detailed report you create, make sure to include a maximum of 3 bullet points that contain the pros and cons of ethics\n",
        "in Generative AI\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "## appending the message to the previous human messages\n",
        "## the HumanMessage now will contain: original prompt --> system response --> new prompt\n",
        "messages.append(HumanMessage(content=prompt_txt))\n",
        "\n",
        "# user_instruction\n",
        "user_instruction = {'instruction': messages}\n",
        "\n",
        "# invoke response\n",
        "response = chain.invoke(user_instruction)\n",
        "messages.append(response)"
      ],
      "metadata": {
        "id": "pVtcDY7WxHve"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNuGbveX3Yka",
        "outputId": "2503b63d-ee73-459b-db0f-ec03c398b87a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='**Detailed Report for Healthcare Company:**\\n\\nThe use of generative artificial intelligence (AI), such as ChatGPT, in high-stakes applications like healthcare has raised ethical concerns. While guidelines and regulations are still evolving, there is a need to address gaps in ethical discussions. A systematic review highlighted the importance of an ethics checklist for transparent documentation in generative AI development.\\n\\nIn healthcare, generative AI is being used for text, image, and structured data. Ethical considerations vary across these modalities, with a focus on issues like privacy, bias reduction, and misinformation detection. While some articles propose solutions using generative AI, others highlight ethical dilemmas caused by these technologies.\\n\\nFor image and structured data, privacy concerns are a key focus, with efforts to generate synthetic data to mitigate risks. However, discussions on autonomy, integrity, and morality issues are lacking. Overall, there is a need for comprehensive ethical assessments and transparency in the development of generative AI-powered products for healthcare applications.\\n\\n**Pros and Cons of Ethics in Generative AI:**\\n- **Pros:**\\n  - Ethical considerations in generative AI can lead to the development of more responsible and trustworthy AI systems.\\n  - Addressing ethical issues can enhance user trust and acceptance of generative AI-powered healthcare products.\\n  - Ethical frameworks can guide the responsible use of generative AI, ensuring patient privacy and data security.\\n\\n- **Cons:**\\n  - Ethical discussions may slow down the pace of innovation and implementation of generative AI in healthcare.\\n  - Resolving ethical dilemmas in generative AI development can be complex and resource-intensive.\\n  - Lack of clear ethical guidelines may lead to unintended consequences and potential harm to patients and healthcare systems.', response_metadata={'token_usage': {'completion_tokens': 345, 'prompt_tokens': 1691, 'total_tokens': 2036}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-73be7906-ebae-4f8f-bc11-aab51302289a-0')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdqz25N73aYf",
        "outputId": "d163a86f-e688-44fd-e249-cf08af25f783"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Detailed Report for Healthcare Company:**\n",
            "\n",
            "The use of generative artificial intelligence (AI), such as ChatGPT, in high-stakes applications like healthcare has raised ethical concerns. While guidelines and regulations are still evolving, there is a need to address gaps in ethical discussions. A systematic review highlighted the importance of an ethics checklist for transparent documentation in generative AI development.\n",
            "\n",
            "In healthcare, generative AI is being used for text, image, and structured data. Ethical considerations vary across these modalities, with a focus on issues like privacy, bias reduction, and misinformation detection. While some articles propose solutions using generative AI, others highlight ethical dilemmas caused by these technologies.\n",
            "\n",
            "For image and structured data, privacy concerns are a key focus, with efforts to generate synthetic data to mitigate risks. However, discussions on autonomy, integrity, and morality issues are lacking. Overall, there is a need for comprehensive ethical assessments and transparency in the development of generative AI-powered products for healthcare applications.\n",
            "\n",
            "**Pros and Cons of Ethics in Generative AI:**\n",
            "- **Pros:**\n",
            "  - Ethical considerations in generative AI can lead to the development of more responsible and trustworthy AI systems.\n",
            "  - Addressing ethical issues can enhance user trust and acceptance of generative AI-powered healthcare products.\n",
            "  - Ethical frameworks can guide the responsible use of generative AI, ensuring patient privacy and data security.\n",
            "\n",
            "- **Cons:**\n",
            "  - Ethical discussions may slow down the pace of innovation and implementation of generative AI in healthcare.\n",
            "  - Resolving ethical dilemmas in generative AI development can be complex and resource-intensive.\n",
            "  - Lack of clear ethical guidelines may lead to unintended consequences and potential harm to patients and healthcare systems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check history of messages so far...."
      ],
      "metadata": {
        "id": "79LP5NQH3hGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdGAwR_D3b-c",
        "outputId": "4ee11bec-ecad-4567-c3c0-e9e2261cceec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='\\nBased on the following research paper abstract,\\ncreate a summary report of maximum 10 lines\\nfor a general audience of stakeholders\\n\\nAbstract:\\n\\nThe widespread use of ChatGPT and other emerging technology powered by generative\\nartificial intelligence (AI) has drawn much attention to potential ethical issues, especially in\\nhigh-stakes applications such as healthcare.1–3 However, less clear is how to resolve such\\nissues beyond following guidelines and regulations that are still under discussion and\\ndevelopment. On the other hand, other types of generative AI have been used to synthesize\\nimages and other types of data for research and practical purposes, which have resolved some\\nethical issues and exposed other ethical issues,4,5 but such technology is less often the focus\\nof ongoing ethical discussions. Here we highlight gaps in current ethical discussions of\\ngenerative AI via a systematic scoping review of relevant existing research in healthcare, and\\nreduce the gaps by proposing an ethics checklist for comprehensive assessment and\\ntransparent documentation of ethical discussions in generative AI development. While the\\nchecklist can be readily integrated into the current peer review and publication system to\\nenhance generative AI research, it may also be used in broader settings to disclose ethicsrelated considerations in generative AI-powered products (or real-life applications of such\\nproducts) to help users establish reasonable trust in their capabilities.\\n\\nCurrent ethical discussions on generative AI in healthcare\\nWe conducted a systematic scoping review to analyse current ethical discussions on\\ngenerative AI in healthcare. Our search in four major academic research databases for\\nrelevant publications from January 2013 to July 2023 yielded 2859 articles (see Methods for\\ndetailed search strategy and Supplementary Figure S1 for the PRISMA flow diagram), of\\nwhich 193 articles were included for analysis based on application data modality (text, image,\\nor structured data), ethical issues discussed, generative AI involved, and whether generative\\nAI causes or offers technical solutions for issues raised.\\n\\nGenerative AI for text data-based healthcare\\nForty-one of the 193 articles discussed ethical considerations pertaining to generative AI\\napplications for text data, with 20 articles describing methodological developments or\\napplications of generative AI and the other 21 articles describing review-type works on this\\ntopic. Although some of these review-type articles used the general term “generative AI”, the\\nmain body and supporting evidence focused on LLMs. Twenty-nine articles had in-depth\\ndiscussions on ethical issues, whereas the other 12 articles only briefly touched on some\\nethical aspects.\\nAmong the 41 articles, 29 articles focused on discussing ethical issues caused by LLMs (and\\nspecifically by GPT in 16 of the articles), covering a wide range of application scenarios and\\nconsidered the application of all 10 ethical principles identified in the review (see Figure 1),\\nas well as other less discussed concerns such as human-AI interaction, and the rights of\\nLLMs to be considered as co-authors in scientific papers. One paper only commented briefly\\non the need for ethical considerations in LLMs and is summarised in the “Others” category.\\nAlthough all ethical principles are equally important, some are discussed more often than\\nothers, e.g., non-maleficence (also referred to in the literature as ‘benevolence’), equity, and\\nprivacy.\\nFifteen of the 41 articles aimed to resolve some existing ethical issues (for example,\\nconfidentiality of medical data) by using LLMs and other generative AI (e.g., GAN,\\nautoencoder or diffusion), such as, to reduce privacy concerns by generating synthetic\\nmedical text, to reduce disparity by providing accessible services and assistance, to detect\\nhealth-related misinformation, to generate trusted content, and to improve accountability or\\ntransparency over existing approaches. While most articles focused on either identifying\\nethical issues caused by generative AI or proposing generative AI-based solutions, three\\narticles discussed both to provide a more balanced perspective.\\n\\nGenerative AI for image and structured data-based healthcare\\nUnlike the diverse application scenarios of generative AI based on text data, for image and\\nstructured data, this use of generative AI focuses on data synthesis and encryption. Hence the\\nmajority of articles discussed the methodological developments of generative AI as giving\\nrise to a more distinctive and focused set of ethical issues.\\n5\\nNotably, of the 98 articles on image data and 58 articles on structured data, more than half\\n(n=63 for image data and n=33 for structured data) only mentioned ethical considerations as a\\nbrief motivation for methodological developments or as a general discussion point. The rest\\nincluded more in-depth discussions or evaluations of ethical issues. Among these 155 articles\\n(as one article covered multiple modalities), 11 articles were review-type work, where 10\\narticles reviewed methods that mentioned one or two ethical perspectives, and only one\\narticle24 discussed detailed ethical concerns on generative AI applications.\\nResolving privacy issues was the main aim of articles for these two data modalities (n=74 for\\nimage data and n=50 for structured data; see Figure 1), predominantly by generating synthetic\\ndata using GAN. Eight articles on image data and 9 articles on structured data used\\ngenerative AI to reduce bias, e.g., by synthesizing data for under-represented subgroups in\\nexisting databases. For both data modalities, we did not see explicit discussions on resolving\\nautonomy, integrity, or morality issues using generative AI, and for structured data the articles\\nadditionally lacked discussions on trust or transparency.\\nOnly 11 articles for image data selectively discussed some ethical issues that generative AI\\ncan give rise to, without specific discussions regarding autonomy, integrity, or morality. For\\nstructured data, only 4 articles discussed equity, privacy, or data security issues caused by\\ngenerative AI. Only two articles on structured data included both the cause and resolving\\nperspectives by discussing ethical issues that may arise from limitations of methods\\nproposed, specifically bias induced when synthesizing data in order to resolve privacy issues.\\n\\n'),\n",
              " AIMessage(content='Summary Report:\\n\\nThe use of generative artificial intelligence (AI), such as ChatGPT, in high-stakes applications like healthcare has raised ethical concerns. While guidelines and regulations are still evolving, there is a need to address gaps in ethical discussions. A systematic review highlighted the importance of an ethics checklist for transparent documentation in generative AI development. \\n\\nIn healthcare, generative AI is being used for text, image, and structured data. Ethical considerations vary across these modalities, with a focus on issues like privacy, bias reduction, and misinformation detection. While some articles propose solutions using generative AI, others highlight ethical dilemmas caused by these technologies. \\n\\nFor image and structured data, privacy concerns are a key focus, with efforts to generate synthetic data to mitigate risks. However, discussions on autonomy, integrity, and morality issues are lacking. Overall, there is a need for comprehensive ethical assessments and transparency in the development of generative AI-powered products for healthcare applications.', response_metadata={'token_usage': {'completion_tokens': 195, 'prompt_tokens': 1334, 'total_tokens': 1529}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-143e4b64-8ade-4a2b-ac1c-94888c052995-0'),\n",
              " HumanMessage(content='\\nUse only the research paper abstract from earlier and create a detailed report for a healthcare company.\\nIn the detailed report you create, make sure to include a maximum of 3 bullet points that contain the pros and cons of ethics\\nin Generative AI\\n\\n'),\n",
              " AIMessage(content='**Detailed Report for Healthcare Company:**\\n\\nThe use of generative artificial intelligence (AI), such as ChatGPT, in high-stakes applications like healthcare has raised ethical concerns. While guidelines and regulations are still evolving, there is a need to address gaps in ethical discussions. A systematic review highlighted the importance of an ethics checklist for transparent documentation in generative AI development.\\n\\nIn healthcare, generative AI is being used for text, image, and structured data. Ethical considerations vary across these modalities, with a focus on issues like privacy, bias reduction, and misinformation detection. While some articles propose solutions using generative AI, others highlight ethical dilemmas caused by these technologies.\\n\\nFor image and structured data, privacy concerns are a key focus, with efforts to generate synthetic data to mitigate risks. However, discussions on autonomy, integrity, and morality issues are lacking. Overall, there is a need for comprehensive ethical assessments and transparency in the development of generative AI-powered products for healthcare applications.\\n\\n**Pros and Cons of Ethics in Generative AI:**\\n- **Pros:**\\n  - Ethical considerations in generative AI can lead to the development of more responsible and trustworthy AI systems.\\n  - Addressing ethical issues can enhance user trust and acceptance of generative AI-powered healthcare products.\\n  - Ethical frameworks can guide the responsible use of generative AI, ensuring patient privacy and data security.\\n\\n- **Cons:**\\n  - Ethical discussions may slow down the pace of innovation and implementation of generative AI in healthcare.\\n  - Resolving ethical dilemmas in generative AI development can be complex and resource-intensive.\\n  - Lack of clear ethical guidelines may lead to unintended consequences and potential harm to patients and healthcare systems.', response_metadata={'token_usage': {'completion_tokens': 345, 'prompt_tokens': 1691, 'total_tokens': 2036}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-73be7906-ebae-4f8f-bc11-aab51302289a-0')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Summary Report #3\n",
        "* Now we add the previous LLM responses and new instructions to the list of messages and pass the entire thing to the LLM so it has access to the historical conversation."
      ],
      "metadata": {
        "id": "WjVS7Fc43ndk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 3rd prompt\n",
        "prompt_txt = f\"\"\"\n",
        "Use only the research paper abstract from earlier and create a detailed report for a Generative AI company that is solving healthcare problems using structured data.\n",
        "In this report please include the following sections with maximum 3 key points in each section related to issues with structured data in healthcare:\n",
        "1. Generative AI for text\n",
        "2. Generative AI for images\n",
        "3. Generative AI for structured data\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "## append message history\n",
        "messages.append(HumanMessage(content=prompt_txt))\n",
        "\n",
        "# user instruction\n",
        "user_instruction = {'instruction': messages}\n",
        "\n",
        "# response\n",
        "response = chain.invoke(user_instruction)"
      ],
      "metadata": {
        "id": "rq2Czdjj3kB6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqfHXX8w4hT8",
        "outputId": "9ff9c07c-5c28-42f8-9918-469d0f44b2e2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='**Detailed Report for Generative AI Company in Healthcare (Structured Data Focus):**\\n\\nThe use of generative artificial intelligence (AI), such as ChatGPT, in high-stakes healthcare applications has brought attention to ethical concerns. Guidelines and regulations are evolving, emphasizing the need for comprehensive ethical assessments and transparency in development.\\n\\n**Generative AI for Text:**\\n- Ethical considerations in text-based generative AI applications are crucial for maintaining patient privacy and ensuring trustworthy outputs.\\n- Issues such as misinformation detection and human-AI interaction need to be addressed to build user trust in AI-powered healthcare solutions.\\n- Clear ethical guidelines can guide the responsible development and deployment of generative AI for text data in healthcare.\\n\\n**Generative AI for Images:**\\n- Privacy concerns are a significant focus in generative AI applications for image data, with efforts to generate synthetic data to mitigate risks.\\n- Addressing bias reduction through generative AI can help in providing more inclusive and accurate healthcare solutions.\\n- Lack of discussions on autonomy, integrity, and morality issues in image data applications highlights the need for a more comprehensive ethical framework.\\n\\n**Generative AI for Structured Data:**\\n- Privacy issues are a key concern in structured data applications, with a focus on using generative AI to generate synthetic data for privacy protection.\\n- Discussions on resolving autonomy, integrity, and morality issues in structured data applications using generative AI are lacking.\\n- The development of clear ethical guidelines for structured data applications is essential to ensure the responsible and ethical use of generative AI in healthcare.\\n\\nBy addressing these key points and focusing on ethical considerations, generative AI companies can contribute to the development of trustworthy and responsible healthcare solutions using structured data.', response_metadata={'token_usage': {'completion_tokens': 336, 'prompt_tokens': 2238, 'total_tokens': 2574}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-72b1fd3d-eb3e-4236-906b-e4b5dc3984a0-0')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## actual response\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfJf7kMl4j-Z",
        "outputId": "ae9113ee-e1bb-4752-87c9-2d1f74628f34"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Detailed Report for Generative AI Company in Healthcare (Structured Data Focus):**\n",
            "\n",
            "The use of generative artificial intelligence (AI), such as ChatGPT, in high-stakes healthcare applications has brought attention to ethical concerns. Guidelines and regulations are evolving, emphasizing the need for comprehensive ethical assessments and transparency in development.\n",
            "\n",
            "**Generative AI for Text:**\n",
            "- Ethical considerations in text-based generative AI applications are crucial for maintaining patient privacy and ensuring trustworthy outputs.\n",
            "- Issues such as misinformation detection and human-AI interaction need to be addressed to build user trust in AI-powered healthcare solutions.\n",
            "- Clear ethical guidelines can guide the responsible development and deployment of generative AI for text data in healthcare.\n",
            "\n",
            "**Generative AI for Images:**\n",
            "- Privacy concerns are a significant focus in generative AI applications for image data, with efforts to generate synthetic data to mitigate risks.\n",
            "- Addressing bias reduction through generative AI can help in providing more inclusive and accurate healthcare solutions.\n",
            "- Lack of discussions on autonomy, integrity, and morality issues in image data applications highlights the need for a more comprehensive ethical framework.\n",
            "\n",
            "**Generative AI for Structured Data:**\n",
            "- Privacy issues are a key concern in structured data applications, with a focus on using generative AI to generate synthetic data for privacy protection.\n",
            "- Discussions on resolving autonomy, integrity, and morality issues in structured data applications using generative AI are lacking.\n",
            "- The development of clear ethical guidelines for structured data applications is essential to ensure the responsible and ethical use of generative AI in healthcare.\n",
            "\n",
            "By addressing these key points and focusing on ethical considerations, generative AI companies can contribute to the development of trustworthy and responsible healthcare solutions using structured data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "* What we were able to do was use the `ChatPromptTemplate` and `HumanMessages` to store our conversation history as we went and refer to the context of the `HumanMessages` as we went along to give the LLM the conversation history for every new prompt.\n",
        "* There are some better ways to do this, this is the \"basic\" way to create a \"chatbot\" with your data. There are more efficient ways to do this which I will cover in a separate project."
      ],
      "metadata": {
        "id": "dxYk38lU43fm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ZzYLasL4mXL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}